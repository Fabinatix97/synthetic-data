
@book{hradec_multipurpose_2022,
	address = {Luxembourg},
	series = {{JRC} {Technical} {Report}},
	title = {Multipurpose synthetic population for policy applications},
	isbn = {978-92-76-53478-5},
	url = {https://publications.jrc.ec.europa.eu/repository/handle/JRC128595},
	abstract = {While privacy preservation is a major topic today, until recently, striking the balance between usefulness and detail in data was achieved by aggregation on linear scale. New methods for handling analytics however allow to close this gap and to preserve both privacy and knowledge. Compared to other privacy-preservation techniques, synthetic data can have the best value/effort performance. 

    Synthetic population models facilitate application of novel methods for data-driven policy formulation and evaluation, representing a unique opportunity. This report showcases several applications of structured population such as population activity-based modelling, knock-on effects of selective lock-downs during the COVID-19 pandemic, investigative analysis of existing policy instrument design in the energy transition domain, and applications for synthetic cancer patient records.
    
    The text carefully weighs pros and cons of synthetic data in these policy applications to provide actionable insights for decision makers on opportunities and reliability of advice based on synthetic data. Such data can become unifying bridge between policy support computational models, provide data hidden in silos, and become the key enabler of artificial intelligence in business and policy applications in Europe. Synthetic data have potential help controlling unevenness and bias in algorithmic governance and enable better targeted policies with small regulatory footprint.},
	language = {en},
	number = {EUR 31116 EN},
	urldate = {2024-06-28},
	publisher = {Publications Office of the European Union},
	author = {Hradec, Jiri and Craglia, Massimo and Di, LEO Margherita and De, NIGRIS Sarah and Ostlaender, Nicole and Nicholson, Nicholas},
	year = {2022},
	file = {JRC128595_01.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\FGGCM4ML\\JRC128595_01.pdf:application/pdf;Snapshot:C\:\\Users\\Fabian\\Zotero\\storage\\VXQ45YXQ\\JRC128595.html:text/html},
}

@article{saadi_hidden_markov_2016,
    title = {Hidden Markov Model-based population synthesis},
    journal = {Transportation Research Part B: Methodological},
    volume = {90},
    pages = {1-21},
    year = {2016},
    issn = {0191-2615},
    doi = {https://doi.org/10.1016/j.trb.2016.04.007},
    url = {https://www.sciencedirect.com/science/article/pii/S0191261515300904},
    author = {Ismaïl Saadi and Ahmed Mustafa and Jacques Teller and Bilal Farooq and Mario Cools},
    keywords = {Hidden Markov Model, Population synthesis, Agent-based micro-simulation transportation modeling, Multiple data sources, Scalability},
    abstract = {Micro-simulation travel demand and land use models require a synthetic population, which consists of a set of agents characterized by demographic and socio-economic attributes. Two main families of population synthesis techniques can be distinguished: (a) fitting methods (iterative proportional fitting, updating) and (b) combinatorial optimization methods. During the last few years, a third outperforming family of population synthesis procedures has emerged, i.e., Markov process-based methods such as Monte Carlo Markov Chain (MCMC) simulations. In this paper, an extended Hidden Markov Model (HMM)-based approach is presented, which can serve as a better alternative than the existing methods. The approach is characterized by a great flexibility and efficiency in terms of data preparation and model training. The HMM is able to reproduce the structural configuration of a given population from an unlimited number of micro-samples and a marginal distribution. Only one marginal distribution of the considered population can be used as a boundary condition to “guide” the synthesis of the whole population. Model training and testing are performed using the Survey on the Workforce of 2013 and the Belgian National Household Travel Survey of 2010. Results indicate that the HMM method captures the complete heterogeneity of the micro-data contrary to standard fitting approaches. The method provides accurate results as it is able to reproduce the marginal distributions and their corresponding multivariate joint distributions with an acceptable error rate (i.e., SRSME=0.54 for 6 synthesized attributes). Furthermore, the HMM outperforms IPF for small sample sizes, even though the amount of input data is less than that for IPF. Finally, simulations show that the HMM can merge information provided by multiple data sources to allow good population estimates.}
}

@article{gogoshin_synthetic_2021,
	title = {Synthetic data generation with probabilistic {Bayesian} {Networks}},
	volume = {18},
	issn = {1547-1063},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8848551/},
	doi = {10.3934/mbe.2021426},
	abstract = {Bayesian Network (BN) modeling is a prominent and increasingly popular computational systems biology method. It aims to construct network graphs from the large heterogeneous biological datasets that reflect the underlying biological relationships. Currently, a variety of strategies exist for evaluating BN methodology performance, ranging from utilizing artificial benchmark datasets and models, to specialized biological benchmark datasets, to simulation studies that generate synthetic data from predefined network models. The last is arguably the most comprehensive approach; however, existing implementations often rely on explicit and implicit assumptions that may be unrealistic in a typical biological data analysis scenario, or are poorly equipped for automated arbitrary model generation. In this study, we develop a purely probabilistic simulation framework that addresses the demands of statistically sound simulations studies in an unbiased fashion. Additionally, we expand on our current understanding of the theoretical notions of causality and dependence / conditional independence in BNs and the Markov Blankets within.},
	number = {6},
	urldate = {2024-06-28},
	journal = {Mathematical biosciences and engineering : MBE},
	author = {Gogoshin, Grigoriy and Branciamore, Sergio and Rodin, Andrei S.},
	year = {2021},
	pmid = {34814315},
	pmcid = {PMC8848551},
	pages = {8603--8621},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Fabian\\Zotero\\storage\\3M8CADMQ\\Gogoshin et al. - 2021 - Synthetic data generation with probabilistic Bayes.pdf:application/pdf},
}

@article{young_using_2009,
	title = {Using {Bayesian} {Networks} to {Create} {Synthetic} {Data}},
	volume = {25},
	abstract = {A Bayesian network is a graphical model of the joint probability distribution for a set of variables. A Bayesian network could be used to create multiple synthetic data sets that are then released by an official statistics agency while the original data remain confidential, so that an analyst outside the agency can explore associations between an attribute of interest and other variables. The process is illustrated with an example. Inferences from the original data are compared to inferences from synthetic data created by a single Bayesian network and by Bayesian model averaging over a set of networks. Informative prior information is needed in order to assign appropriate weights to each network in this set if synthetic data are to have both good inferential properties and an acceptable risk of disclosure. This sensitivity to prior information will make it difficult for an official statistics agency to use Bayesian networks to automate the process of creating synthetic data.},
	journal = {Journal of Official Statistics},
	author = {Young, Jim and Graham, Patrick and Penny, Richard},
	year = {2009},
	pages = {549--567},
	file = {Young et al. - 2009 - Using Bayesian Networks to Create Synthetic Data.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\J6MXQTZ6\\Young et al. - 2009 - Using Bayesian Networks to Create Synthetic Data.pdf:application/pdf},
}

@phdthesis{huertas_generating_2018,
	address = {Stockholm},
	type = {Final degree project},
	title = {Generating synthetic data  through {Hidden} {Markov}  {Models}},
	url = {https://www.diva-portal.org/smash/get/diva2:1250179/FULLTEXT01.pdf},
	abstract = {Machine learning has becoming a trending topic in the last years, being now one of the most demanding careers in computer science. This growing has lead to more complex models capable of driving a car or cancer detection, however this models improvements are also thanks to the improvements in computational power. In this study we investigate a data exploration technique for creating synthetic data, a field of Machine learning that does not have as much improvements in the last years. Our project comes from a industrial process where data is a valuable asset, this process has both computational power and power full models but struggles with the availability of the data. In response for this a model for generating data is proposed, aiming to fill the lack of data during data exploration and training of this industrial process.

This model consist of a Hidden Markov Model where states represent different distributions the data follows, data is created by traveling through this states with an algorithm that uses the prior distribution of these states in a Dirichlet distribution. 

The method to infer data distributions from the given data and create this Hidden Markov Model model has been explained along with the technique used to travel between states. Results have been presented showing how the data inferring performed and how the synthetic data reproduces the original one, taking special care for the reproduction of specific features in the original data. To get a better perspective of the data we created we tricked the states for our model, creating data from all of the states or from the states with less prior probability. Results showed that the model is capable of creating data similar to the real one but it struggled with data with a small amount of significant outliers. In conclusion a model to create reliable data have been introduced along with a list of possible improvements.},
	language = {en},
	school = {KTH Royal Institute of Technology},
	author = {Huertas, Jaime Ferrando},
	year = {2018},
	file = {FULLTEXT01.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\4N8SHGC9\\FULLTEXT01.pdf:application/pdf},
}

@article{dahmen_synsys_2019,
	title = {{SynSys}: {A} {Synthetic} {Data} {Generation} {System} for {Healthcare} {Applications}},
	volume = {19},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	shorttitle = {{SynSys}},
	url = {https://www.mdpi.com/1424-8220/19/5/1181},
	doi = {10.3390/s19051181},
	abstract = {Creation of realistic synthetic behavior-based sensor data is an important aspect of testing machine learning techniques for healthcare applications. Many of the existing approaches for generating synthetic data are often limited in terms of complexity and realism. We introduce SynSys, a machine learning-based synthetic data generation method, to improve upon these limitations. We use this method to generate synthetic time series data that is composed of nested sequences using hidden Markov models and regression models which are initially trained on real datasets. We test our synthetic data generation technique on a real annotated smart home dataset. We use time series distance measures as a baseline to determine how realistic the generated data is compared to real data and demonstrate that SynSys produces more realistic data in terms of distance compared to random data generation, data from another home, and data from another time period. Finally, we apply our synthetic data generation technique to the problem of generating data when only a small amount of ground truth data is available. Using semi-supervised learning we demonstrate that SynSys is able to improve activity recognition accuracy compared to using the small amount of real data alone.},
	language = {en},
	number = {5},
	urldate = {2024-06-28},
	journal = {Sensors},
	author = {Dahmen, Jessamyn and Cook, Diane},
	year = {2019},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {activity recognition, healthcare data, hidden Markov models, regression, smart homes, Synthetic data},
	pages = {1181},
	file = {Full Text PDF:C\:\\Users\\Fabian\\Zotero\\storage\\DJ8SH8BZ\\Dahmen und Cook - 2019 - SynSys A Synthetic Data Generation System for Hea.pdf:application/pdf},
}


@article{kaur_application_2020,
	title = {Application of {Bayesian} networks to generate synthetic health data},
	volume = {28},
	issn = {1067-5027},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7973486/},
	doi = {10.1093/jamia/ocaa303},
	abstract = {Objective
This study seeks to develop a fully automated method of generating synthetic data from a real dataset that could be employed by medical organizations to distribute health data to researchers, reducing the need for access to real data. We hypothesize the application of Bayesian networks will improve upon the predominant existing method, medBGAN, in handling the complexity and dimensionality of healthcare data.

Materials and Methods
We employed Bayesian networks to learn probabilistic graphical structures and simulated synthetic patient records from the learned structure. We used the University of California Irvine (UCI) heart disease and diabetes datasets as well as the MIMIC-III diagnoses database. We evaluated our method through statistical tests, machine learning tasks, preservation of rare events, disclosure risk, and the ability of a machine learning classifier to discriminate between the real and synthetic data.

Results
Our Bayesian network model outperformed or equaled medBGAN in all key metrics. Notable improvement was achieved in capturing rare variables and preserving association rules.

Discussion
Bayesian networks generated data sufficiently similar to the original data with minimal risk of disclosure, while offering additional transparency, computational efficiency, and capacity to handle more data types in comparison to existing methods. We hope this method will allow healthcare organizations to efficiently disseminate synthetic health data to researchers, enabling them to generate hypotheses and develop analytical tools. 

Conclusion
We conclude the application of Bayesian networks is a promising option for generating realistic synthetic health data that preserves the features of the original data without compromising data privacy.},
	number = {4},
	urldate = {2024-06-28},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Kaur, Dhamanpreet and Sobiesk, Matthew and Patil, Shubham and Liu, Jin and Bhagat, Puran and Gupta, Amar and Markuzon, Natasha},
	year = {2020},
	pmid = {33367620},
	pmcid = {PMC7973486},
	pages = {801--811},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Fabian\\Zotero\\storage\\YQD8DNA3\\Kaur et al. - 2020 - Application of Bayesian networks to generate synth.pdf:application/pdf},
}

@misc{jordon_synthetic_2022,
	title = {Synthetic {Data} -- what, why and how?},
	url = {http://arxiv.org/abs/2205.03257},
	doi = {10.48550/arXiv.2205.03257},
	abstract = {This explainer document aims to provide an overview of the current state of the rapidly expanding work on synthetic data technologies, with a particular focus on privacy. The article is intended for a non-technical audience, though some formal definitions have been given to provide clarity to specialists. This article is intended to enable the reader to quickly become familiar with the notion of synthetic data, as well as understand some of the subtle intricacies that come with it. We do believe that synthetic data is a very useful tool, and our hope is that this report highlights that, while drawing attention to nuances that can easily be overlooked in its deployment.},
	urldate = {2024-06-28},
	publisher = {arXiv},
	author = {Jordon, James and Szpruch, Lukasz and Houssiau, Florimond and Bottarelli, Mirko and Cherubin, Giovanni and Maple, Carsten and Cohen, Samuel N. and Weller, Adrian},
	year = {2022},
	note = {arXiv:2205.03257 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Fabian\\Zotero\\storage\\BJKQXUML\\Jordon et al. - 2022 - Synthetic Data -- what, why and how.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Fabian\\Zotero\\storage\\GUPQR89B\\2205.html:text/html},
}

@misc{shrivastava_learning_2017,
	title = {Learning from {Simulated} and {Unsupervised} {Images} through {Adversarial} {Training}},
	url = {http://arxiv.org/abs/1612.07828},
	doi = {10.48550/arXiv.1612.07828},
	abstract = {With recent progress in graphics, it has become more tractable to train models on synthetic images, potentially avoiding the need for expensive annotations. However, learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap, we propose Simulated+Unsupervised (S+U) learning, where the task is to learn a model to improve the realism of a simulator's output using unlabeled real data, while preserving the annotation information from the simulator. We develop a method for S+U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs), but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations, avoid artifacts, and stabilize training: (i) a 'self-regularization' term, (ii) a local adversarial loss, and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images, which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data.},
	urldate = {2024-06-28},
	publisher = {arXiv},
	author = {Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Josh and Wang, Wenda and Webb, Russ},
	year = {2017},
	note = {arXiv:1612.07828 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\Fabian\\Zotero\\storage\\C6THNSAU\\Shrivastava et al. - 2017 - Learning from Simulated and Unsupervised Images th.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Fabian\\Zotero\\storage\\GKVZAHIK\\1612.html:text/html},
}

@book{bieker_open_2019,
	address = {Berlin},
	edition = {1},
	title = {Open {Data} - zwischen {Wunsch} und {Wirklichkeit}},
	isbn = {978-3-9819921-4-4},
	url = {https://publica-rest.fraunhofer.de/server/api/core/bitstreams/d7c84a82-62b6-4954-abd7-c39caf3f6730/content},
	abstract = {Open Data soll die Zusammenarbeit zwischen Behörden verbessern, die Transparenz von Politik erhöhen und neue Geschäftsmodelle ermöglichen. Die Ansprüche an die Verwaltung sind hoch, doch bei der Umsetzung zeigen sich Hürden. Kritiker führen an, dass offene Daten nur selten genutzt werden. Grund genug, eine Zwischenbilanz zu ziehen. Anhand von vier europäischen Metropolen arbeiten wir in dieser Studie nicht nur Unterschiede in der Umsetzung von Open Data heraus, sondern gehen auch auf die jeweilige Nutzung ein. Was passiert, wenn politische Versprechen auf Verwaltungswirklichkeit treffen? Wir laden Sie zur Beantwortung dieser Frage auf eine Reise nach London, Hamburg, Berlin und Wien ein. Unterwegs erfahren Sie, wie Open-Data-Ökosysteme entstehen und was für eine erfolgreiche Umsetzung von Open Data ausschlaggebend ist.},
	language = {de},
	publisher = {Fraunhofer-Institut für Offene Kommunikationssysteme FOKUS},
	author = {Bieker, Lisa and Bruns, Lina and Thapa, Basanta E. P. and Welzel, Christian},
	year = {2019},
	file = {Bieker et al. - Open Data zwischen Wunsch und Wirklichkeit.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\Y8SJJ995\\Bieker et al. - Open Data zwischen Wunsch und Wirklichkeit.pdf:application/pdf},
}

@incollection{wewer_offene_2019,
	address = {Wiesbaden},
	title = {Offene {Daten} ({Open} {Data})},
	isbn = {978-3-658-21563-7},
	url = {https://doi.org/10.1007/978-3-658-21563-7_49},
	abstract = {Staatliche oder kommunale Daten, die digital verfügbar sind, gelten dann als „offen“, wenn sie von jedermann beliebig genutzt werden können. Wenn die Verwaltung ihre Datenbestände grundsätzlich veröffentlicht und in Formaten bereitstellt, dass andere sie verarbeiten können, dann erhofft man sich nützliche Anwendungen, die Innovationen fördern und das wirtschaftliche Wachstum antreiben. Auch Behörden können davon profitieren, etwa durch einen leichteren Zugriff auf die Daten anderer Stellen. Offene Daten könnten deshalb nicht nur eine relativ kostengünstige Wirtschaftsförderung sein, sondern auch Impulse zur Modernisierung der Verwaltung geben. Fehler in den Daten können schneller entdeckt werden, wenn viele damit arbeiten, und es können Anwendungen entstehen, die bei den begrenzten Ressourcen der Verwaltung nicht hätten erwartet werden können.},
	language = {de},
	urldate = {2024-06-28},
	booktitle = {Handbuch zur {Verwaltungsreform}},
	publisher = {Springer Fachmedien},
	author = {Wewer, Göttrik},
	editor = {Veit, Sylvia and Reichard, Christoph and Wewer, Göttrik},
	year = {2019},
	doi = {10.1007/978-3-658-21563-7_49},
	keywords = {Innovationen, Open Access, Open Government Data, Transparenz, Wirtschaftsförderung},
	pages = {559--570},
	file = {Full Text PDF:C\:\\Users\\Fabian\\Zotero\\storage\\6ZHLI4R2\\Wewer - 2019 - Offene Daten (Open Data).pdf:application/pdf},
}

@book{gumz_anonymisierung_2019,
	address = {Berlin},
	edition = {1},
	title = {Anonymisierung:  {Schutzziele} und {Techniken}},
	isbn = {978-3-9819921-2-0},
	url = {https://publica-rest.fraunhofer.de/server/api/core/bitstreams/43b93fce-4626-4627-ab6a-9790528a507f/content},
    abstract = {Datenschutz ist ein hohes Gut in der digitalen Welt. Wer personenbezogene Daten erheben, auswerten oder weitergeben will muss strenge Vorgaben beachten. Durch die Anonymisierung von Daten kann eine Brücke zwischen den Datenschutzinteressen der Einzelnen und der Nutzung von Daten geschlagen werden. In diesem White Paper erfahren Sie, wie Daten richtig anonymisiert werden und welche Anonymisierungstechniken es gibt.},
	language = {de},
	publisher = {Fraunhofer-Institut für Offene Kommunikationssysteme FOKUS},
	author = {Gumz, Jan Dennis and Weber, Mike and Welzel, Christian},
	year = {2019},
	file = {Gumz et al. - ANONYMISIERUNG  SCHUTZZIELE UND TECHNIKEN.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\XE5N3XPG\\Gumz et al. - ANONYMISIERUNG  SCHUTZZIELE UND TECHNIKEN.pdf:application/pdf},
}

@article{el_emam_evaluating_2020,
	title = {Evaluating {Identity} {Disclosure} {Risk} in {Fully} {Synthetic} {Health} {Data}: {Model} {Development} and {Validation}},
	volume = {22},
	issn = {1438-8871},
	shorttitle = {Evaluating {Identity} {Disclosure} {Risk} in {Fully} {Synthetic} {Health} {Data}},
	url = {http://www.jmir.org/2020/11/e23139/},
	doi = {10.2196/23139},
	abstract = {Background: There has been growing interest in data synthesis for enabling the sharing of data for secondary analysis; however, there is a need for a comprehensive privacy risk model for fully synthetic data: If the generative models have been overfit, then it is possible to identify individuals from synthetic data and learn something new about them.
Objective: The purpose of this study is to develop and apply a methodology for evaluating the identity disclosure risks of fully synthetic data.
Methods: A full risk model is presented, which evaluates both identity disclosure and the ability of an adversary to learn something new if there is a match between a synthetic record and a real person. We term this “meaningful identity disclosure risk.” The model is applied on samples from the Washington State Hospital discharge database (2007) and the Canadian COVID-19 cases database. Both of these datasets were synthesized using a sequential decision tree process commonly used to synthesize health and social science data.
Results: The meaningful identity disclosure risk for both of these synthesized samples was below the commonly used 0.09 risk threshold (0.0198 and 0.0086, respectively), and 4 times and 5 times lower than the risk values for the original datasets, respectively.
Conclusions: We have presented a comprehensive identity disclosure risk model for fully synthetic data. The results for this synthesis method on 2 datasets demonstrate that synthesis can reduce meaningful identity disclosure risks considerably. The risk model can be applied in the future to evaluate the privacy of fully synthetic data.},
	language = {en},
	number = {11},
	urldate = {2024-06-28},
	journal = {Journal of Medical Internet Research},
	author = {El Emam, Khaled and Mosquera, Lucy and Bass, Jason},
	year = {2020},
	pages = {e23139},
	file = {El Emam et al. - 2020 - Evaluating Identity Disclosure Risk in Fully Synth.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\KKDI6JHH\\El Emam et al. - 2020 - Evaluating Identity Disclosure Risk in Fully Synth.pdf:application/pdf},
}

@inproceedings{synthetic_data_vault_2016,
    address = {Montr{\'e}al},
    title = {The Synthetic data vault},
    url = {https://dai.lids.mit.edu/wp-content/uploads/2018/03/SDV.pdf},
    doi = {10.1109/DSAA.2016.49},
    booktitle = {IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
    publisher = {IEEE},
    author = {Patki, Neha and Wedge, Roy and Veeramachaneni, Kalyan},
    year = {2016},
    pages = {399--410},
}

@misc{xu_modeling_2019,
	title = {Modeling {Tabular} data using {Conditional} {GAN}},
	url = {http://arxiv.org/abs/1907.00503},
	abstract = {Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difﬁcult. Existing statistical and deep neural network models fail to properly model this type of data. We design CTGAN, which uses a conditional generator to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. CTGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.},
	language = {en},
	urldate = {2024-06-28},
	publisher = {arXiv},
	author = {Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
	year = {2019},
	note = {arXiv:1907.00503 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Xu et al. - 2019 - Modeling Tabular data using Conditional GAN.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\GHJBR4RA\\Xu et al. - 2019 - Modeling Tabular data using Conditional GAN.pdf:application/pdf},
}

@misc{misc_adult_2,
  author = {Becker, Barry and Kohavi,Ronny},
  title = {{Census Income Dataset}},
  year = {1996},
  howpublished = {UCI Machine Learning Repository},
  doi = {{DOI}: https://doi.org/10.24432/C5XW20}
}

@incollection{dewes_verfahren_2022,
	address = {Berlin, Heidelberg},
	title = {Verfahren zur {Anonymisierung} und {Pseudonymisierung} von {Daten}},
	isbn = {978-3-662-65232-9},
	url = {https://doi.org/10.1007/978-3-662-65232-9_14},
	abstract = {Dieses Kapitel gibt einen Überblick über aktuelle Techniken für die Anonymisierung und Pseudonymisierung von Daten. Nach einer kurzen Einführung in die Thematik sowie der Klärung wesentlicher Begriffe aus rechtlicher und organisatorischer Sicht werden Methoden für die Anonymisierung strukturierter Daten erläutert. Hierbei wird der Schwerpunkt auf aggregationsbasierte Anonymisierung gelegt. Differential Privacy wird als moderne Methodik zur Bewertung rauschbasierter Anonymisierungsverfahren diskutiert und anhand eines Praxisbeispiels erläutert. Es werden Methoden für das Testen von differenziell privaten Anonymisierungsverfahren und Praxisbeispiele vorgestellt, in denen Differential Privacy von Organisationen erfolgreich eingesetzt wird. Anschließend werden Pseudonymisierungsverfahren erläutert. Hierbei werden insbesondere moderne, kryptographische Verfahren betrachtet sowie die struktur- und formaterhaltende Pseudonymisierung von Daten. Die vorgestellten Verfahren werden wiederum anhand von Praxisbeispielen erläutert.},
	language = {de},
	urldate = {2024-06-28},
	booktitle = {Datenwirtschaft und {Datentechnologie}: {Wie} aus {Daten} {Wert} entsteht},
	publisher = {Springer},
	author = {Dewes, Andreas},
	editor = {Rohde, Marieke and Bürger, Matthias and Peneva, Kristina and Mock, Johannes},
	year = {2022},
	doi = {10.1007/978-3-662-65232-9_14},
	pages = {183--201},
	file = {Full Text PDF:C\:\\Users\\Fabian\\Zotero\\storage\\S88335LP\\Dewes - 2022 - Verfahren zur Anonymisierung und Pseudonymisierung.pdf:application/pdf},
}

@article{selvarajoo_towards_2024,
	title = {Towards multi-omics synthetic data integration},
	volume = {25},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1467-5463, 1477-4054},
	url = {https://academic.oup.com/bib/article/doi/10.1093/bib/bbae213/7665591},
	doi = {10.1093/bib/bbae213},
	abstract = {Across many scientific disciplines, the development of computational models and algorithms for generating artificial or synthetic data is gaining momentum. In biology, there is a great opportunity to explore this further as more and more big data at multi-omics level are generated recently. In this opinion, we discuss the latest trends in biological applications based on process-driven and data-driven aspects. Moving ahead, we believe these methodologies can help shape novel multi-omics-scale cellular inferences.},
	language = {en},
	number = {3},
	urldate = {2024-06-28},
	journal = {Briefings in Bioinformatics},
	author = {Selvarajoo, Kumar and Maurer-Stroh, Sebastian},
	year = {2024},
	file = {Selvarajoo und Maurer-Stroh - 2024 - Towards multi-omics synthetic data integration.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\8GXMCX2I\\Selvarajoo und Maurer-Stroh - 2024 - Towards multi-omics synthetic data integration.pdf:application/pdf},
}

@misc{hao_synthetic_2024,
	title = {Synthetic {Data} in {AI}: {Challenges}, {Applications}, and {Ethical} {Implications}},
	shorttitle = {Synthetic {Data} in {AI}},
	url = {http://arxiv.org/abs/2401.01629},
	abstract = {In the rapidly evolving field of artificial intelligence, the creation and utilization of synthetic datasets have become increasingly significant. This report delves into the multifaceted aspects of synthetic data, particularly emphasizing the challenges and potential biases these datasets may harbor. It explores the methodologies behind synthetic data generation, spanning traditional statistical models to advanced deep learning techniques, and examines their applications across diverse domains. The report also critically addresses the ethical considerations and legal implications associated with synthetic datasets, highlighting the urgent need for mechanisms to ensure fairness, mitigate biases, and uphold ethical standards in AI development.},
	language = {en},
	urldate = {2024-06-28},
	publisher = {arXiv},
	author = {Hao, Shuang and Han, Wenfeng and Jiang, Tao and Li, Yiping and Wu, Haonan and Zhong, Chunlin and Zhou, Zhangjun and Tang, He},
	year = {2024},
	note = {arXiv:2401.01629 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
	file = {Hao et al. - 2024 - Synthetic Data in AI Challenges, Applications, an.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\W45AZHXU\\Hao et al. - 2024 - Synthetic Data in AI Challenges, Applications, an.pdf:application/pdf},
}

@phdthesis{van_hoorn_acceptance_2024,
	address = {Eindhoven},
	title = {On the {Acceptance}, {Adoption}, and {Utility} of {Synthetic} {Data} for {Healthcare} {Innovation}},
	url = {https://pure.tue.nl/ws/portalfiles/portal/320803466/Master_Thesis_Robin_van_Hoorn.pdf},
	language = {en},
    urldate = {2024-06-28},
	school = {Eindhoven University of Technology},
	author = {van Hoorn, Robin Daniel},
	year = {2024},
	file = {van Hoorn - On the Acceptance, Adoption, and Utility of Synthe.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\QDQJGA4Z\\van Hoorn - On the Acceptance, Adoption, and Utility of Synthe.pdf:application/pdf},
}

@techreport{schwartmann_praxisleitfaden_2022,
	address = {Leipzig},
	title = {Praxisleitfaden zum {Anonymisieren}  personenbezogener {Daten}},
	url = {https://stiftungdatenschutz.org/fileadmin/Redaktion/Dokumente/Anonymisierung_personenbezogener_Daten/SDS_Studie_Praxisleitfaden-Anonymisieren-Web_01.pdf},
	urldate = {2024-06-28},
	institution = {Stiftung Datenschutz},
	author = {Schwartmann, Rolf and Jaspers, Andreas and Lepperhoff, Niels and Weiß, Steffen},
	collaborator = {Meier, Michael},
	year = {2022},
	file = {SDS_Studie_Praxisleitfaden-Anonymisieren-Web_01.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\WXS6LL4R\\SDS_Studie_Praxisleitfaden-Anonymisieren-Web_01.pdf:application/pdf},
}

@article{lei_xu_information_2014,
	title = {Information {Security} in {Big} {Data}: {Privacy} and {Data} {Mining}},
	volume = {2},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/OAPA.html},
	issn = {2169-3536},
	shorttitle = {Information {Security} in {Big} {Data}},
	url = {http://ieeexplore.ieee.org/document/6919256/},
	doi = {10.1109/ACCESS.2014.2362522},
	abstract = {The growing popularity and development of data mining technologies bring serious threat to the security of individual’s sensitive information. An emerging research topic in data mining, known as privacypreserving data mining (PPDM), has been extensively studied in recent years. The basic idea of PPDM is to modify the data in such a way so as to perform data mining algorithms effectively without compromising the security of sensitive information contained in the data. Current studies of PPDM mainly focus on how to reduce the privacy risk brought by data mining operations, while in fact, unwanted disclosure of sensitive information may also happen in the process of data collecting, data publishing, and information (i.e., the data mining results) delivering. In this paper, we view the privacy issues related to data mining from a wider perspective and investigate various approaches that can help to protect sensitive information. In particular, we identify four different types of users involved in data mining applications, namely, data provider, data collector, data miner, and decision maker. For each type of user, we discuss his privacy concerns and the methods that can be adopted to protect sensitive information. We brieﬂy introduce the basics of related research topics, review state-of-the-art approaches, and present some preliminary thoughts on future research directions. Besides exploring the privacy-preserving approaches for each type of user, we also review the game theoretical approaches, which are proposed for analyzing the interactions among different users in a data mining scenario, each of whom has his own valuation on the sensitive information. By differentiating the responsibilities of different users with respect to security of sensitive information, we would like to provide some useful insights into the study of PPDM.},
	language = {en},
	urldate = {2024-06-28},
	journal = {IEEE Access},
	author = {{Lei Xu} and {Chunxiao Jiang} and {Jian Wang} and {Jian Yuan} and {Yong Ren}},
	year = {2014},
	pages = {1149--1176},
	file = {Lei Xu et al. - 2014 - Information Security in Big Data Privacy and Data.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\MR2YIWHJ\\Lei Xu et al. - 2014 - Information Security in Big Data Privacy and Data.pdf:application/pdf},
}

@article{ramzan_generative_2024,
	title = {Generative {Adversarial} {Networks} for {Synthetic} {Data} {Generation} in {Finance}: {Evaluating} {Statistical} {Similarities} and {Quality} {Assessment}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2673-2688},
	shorttitle = {Generative {Adversarial} {Networks} for {Synthetic} {Data} {Generation} in {Finance}},
	url = {https://www.mdpi.com/2673-2688/5/2/35},
	doi = {10.3390/ai5020035},
	abstract = {Generating synthetic data is a complex task that necessitates accurately replicating the statistical and mathematical properties of the original data elements. In sectors such as finance, utilizing and disseminating real data for research or model development can pose substantial privacy risks owing to the inclusion of sensitive information. Additionally, authentic data may be scarce, particularly in specialized domains where acquiring ample, varied, and high-quality data is difficult or costly. This scarcity or limited data availability can limit the training and testing of machine-learning models. In this paper, we address this challenge. In particular, our task is to synthesize a dataset with similar properties to an input dataset about the stock market. The input dataset is anonymized and consists of very few columns and rows, contains many inconsistencies, such as missing rows and duplicates, and its values are not normalized, scaled, or balanced. We explore the utilization of generative adversarial networks, a deep-learning technique, to generate synthetic data and evaluate its quality compared to the input stock dataset. Our innovation involves generating artificial datasets that mimic the statistical properties of the input elements without revealing complete information. For example, synthetic datasets can capture the distribution of stock prices, trading volumes, and market trends observed in the original dataset. The generated datasets cover a wider range of scenarios and variations, enabling researchers and practitioners to explore different market conditions and investment strategies. This diversity can enhance the robustness and generalization of machine-learning models. We evaluate our synthetic data in terms of the mean, similarities, and correlations.},
	language = {en},
	number = {2},
	urldate = {2024-06-28},
	journal = {AI},
	author = {Ramzan, Faisal and Sartori, Claudio and Consoli, Sergio and Reforgiato Recupero, Diego},
	year = {2024},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {data augmentation, deep learning, generative adversarial networks, synthetic data},
	pages = {667--685},
	file = {Full Text PDF:C\:\\Users\\Fabian\\Zotero\\storage\\XNVBDE75\\Ramzan et al. - 2024 - Generative Adversarial Networks for Synthetic Data.pdf:application/pdf},
}

@inproceedings{chakrabarty_statistical_2018,
	address = {Greater Noida (UP), India},
	title = {A {Statistical} {Approach} to {Adult} {Census} {Income} {Level} {Prediction}},
	isbn = {978-1-5386-4119-4},
	url = {https://ieeexplore.ieee.org/document/8748528/},
	doi = {10.1109/ICACCCN.2018.8748528},
	abstract = {The prominent inequality of wealth and income is a huge concern especially in the United States. The likelihood of diminishing poverty is one valid reason to reduce the world's surging level of economic inequality. The principle of universal moral equality ensures sustainable development and improve the economic stability of a nation. Governments in different countries have been trying their best to address this problem and provide an optimal solution. This study aims to show the usage of machine learning and data mining techniques in providing a solution to the income equality problem. The UCI Adult Dataset has been used for the purpose. Classification has been done to predict whether a person's yearly income in US falls in the income category of either greater than 50K Dollars or less equal to 50K Dollars category based on a certain set of attributes. The Gradient Boosting Classifier Model was deployed which clocked the highest accuracy of 88.16\%, eventually breaking the benchmark accuracy of existing works.},
	language = {en},
	urldate = {2024-06-28},
	booktitle = {2018 {International} {Conference} on {Advances} in {Computing}, {Communication} {Control} and {Networking} ({ICACCCN})},
	publisher = {IEEE},
	author = {Chakrabarty, Navoneel and Biswas, Sanket},
	year = {2018},
	pages = {207--212},
	file = {Chakrabarty und Biswas - 2018 - A Statistical Approach to Adult Census Income Leve.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\DH52SUKH\\Chakrabarty und Biswas - 2018 - A Statistical Approach to Adult Census Income Leve.pdf:application/pdf},
}

@inproceedings{islam_rana_investigation_2024,
	title = {An {Investigation} into the {Prediction} of {Annual} {Income} {Levels} {Through} the {Utilization} of {Demographic} {Features} {Employing} the {Modified} {UCI} {Adult} {Dataset}},
	doi = {10.1109/ICCCIS60361.2023.10425394},
	author = {Islam Rana, Cp Md and Nag, Anindya and Roy, Nilanjana and Dey, Arpita and Fahim, SM and Ghosh, Arjan},
	year = {2024},
	doi = {10.1109/ICCCIS60361.2023.10425394},
	note = {Pages: 1086},
	pages = {1080--1086},
}

@inproceedings{lazar_income_2004,
	address = {Louisville, Kentucky, USA},
	title = {Income prediction via support vector machine},
	isbn = {978-0-7803-8823-9},
	url = {http://ieeexplore.ieee.org/document/1383506/},
	doi = {10.1109/ICMLA.2004.1383506},
	abstract = {Principal component analysis and support vector machine methods are employed to generate and evaluate income prediction data based on the Current Population Survey provided by the U.S. Census Bureau. A detailed statistical study targeted for relevant feature selection is found to increase efficiency and even improve classification accuracy. A systematic study is performed on the influence of this statistical narrowing on the grid parameter search, training time, accuracy, and number of support vectors. Accuracy values as high as 84\%, when compared against a test population, are obtained with a reduced set of parameters while the computational time is reduced by 60\%. Tailoring computational methods around specific real data sets is critical in designing powerful algorithms.},
	language = {en},
	urldate = {2024-06-28},
	booktitle = {2004 {International} {Conference} on {Machine} {Learning} and {Applications}, 2004. {Proceedings}.},
	publisher = {IEEE},
	author = {Lazar, A.},
	year = {2004},
	pages = {143--149},
	file = {Lazar - 2004 - Income prediction via support vector machine.pdf:C\:\\Users\\Fabian\\Zotero\\storage\\WRSVQY82\\Lazar - 2004 - Income prediction via support vector machine.pdf:application/pdf},
}